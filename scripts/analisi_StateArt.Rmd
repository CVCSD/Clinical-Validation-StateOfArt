---
title: Clinical Validation of Digital Healthcare Solutions State of the Art, Challenges and Opportunities
author: "Jordi Real. Impuls digital"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: yes
    toc_float: yes
    fig_caption: yes
    css: logos_css/usr_styles.css

subtitle: Bibliometric and visual analysis. Statistical report
website: https://github.com/jrealgatius/
bibliography: references.bib
---

&nbsp;
<script>
   $(document).ready(function() {
     $head = $('#header');
     <!-- $head.prepend('<img src=\"https://www.idiapjgol.org/images/logo.png\" style=\"float: right ;width: 130px;\"/>') -->
     <!-- $head.prepend('<img src=\"https://avatars2.githubusercontent.com/u/57066591?s=200&v=4\" style=\"margin-left:25% ;width: 80px;\"/>') -->
     <!-- $head.prepend('<img src=\"codi/logos_css/logo_sant_pau.png\" style=\"float: left:1;width: 185px;\"/>') -->
     <!-- $head.prepend('<img src=\"codi/logos_css/logo_santpau.png\" style=\"float: left:1;width: 185px;\"/>') -->
     <!-- $head.prepend('<img src=\"../codi/logos_css/logo_santpau.png\" style=\"float: left:1;width: 185px;\"/>') -->
     $head.prepend('<img src=\"https://www.santpau.cat/o/HOSSPAU-Public-theme/images/CampusAssistencial-Convicencia-Positiu-Logo.svg\" style=\"float: left:1;width: 285px;\"/>')

   });
</script>


<div class="watermark">DRAFT</div>

****


# Objective


To review the state of the art of clinical validation of digital solutions in the field of healthcare. The different methods used to assess the clinical effectiveness and safety of these solutions will be explored, as well as the common challenges encountered in this process. Additionally, best practices in clinical validation will be identified, and future perspectives for a more effective approach in this constantly evolving field will be discussed.



# Status

### Done 

- Definition of search strategy
- Literature search
- Download of abstracts
- Capture of abstract designs
- Journal types
- General description
- Bibliometric analysis (Visual and descriptive)




```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE, include=T,size="huge")

# Notaci√≥ no cientifica dels numeros
# options(scipen = 999)


#######################################################
#
#
# libreries i funcions necessaries
library("dplyr")
library("lubridate")
library("compareGroups")
library("ggplot2")
library("wordcloud2")
library("stringi")
library("webshot2")
library("webshot")
library("htmlwidgets")
library("bibtex")
library("officer")
library("flextable")
library("table1")
library("maps")
library("countrycode")

# 
# path_conductor<-here::here("conductor_variables.xls")



```

```{r lectura_articles_pubmed}


dades<-read.csv2(here::here("data","papers.txt"), sep="|") %>% mutate(PMID=as.character(PMID))

dades_extra<-read.csv2(here::here("data","objects.txt"), sep="|",encoding = "UTF-8") %>% mutate(PMID=as.character(PMID))


dt_cataleg_countries<-read.csv2(here::here("data","Countries.txt"), sep=",",encoding = "UTF-8")

# dades_extra2<-read.csv2(here::here("data","objects_2.txt"), sep="#",encoding = "UTF-8")
# 
# dades_pais<-read.csv2(here::here("data","papers_2.txt"), sep=",",encoding = "UTF-8") %>% select(PMID,COUNTRY)
# 

path_conductor<-here::here("conductor_state_of_art.xls")

path_docs<-here::here("outputs","taules.docx")


```


# Method

```{r contatges}

n_count=count(dades) %>% as.numeric()


```



Based on the articles found in the initial search (without filtering by publication year; n=`r n_count` papers), a bibliometric study was conducted. A dataset was created compiling information for each article: publication year, journal, country of the journal, abstract, keywords, impact factor, quartiles, and categories. A descriptive analysis of the frequencies of the generated variables, graphical analysis, Wordcloud of keywords and Mesh terms, and an analysis of frequencies according to the region and country of the first author of the article were performed. Variables related to the type of design used and domains were generated through searches of words in the title, abstract, and keywords. The list of synonymous words used according to design and domain can be seen in Tables and Annex. Additionally, the scope of application and the journal quartile were captured.

A bivariate descriptive table of terms related to the domain in relation to the study design (Observational / Experimental) was performed. Data management and analysis were performed using @R-base, bivariate tables were generated using the package @R-compareGroups, @compareGroups2014, and graphical analysis was performed using R packages @R-ggplot2, @R-wordcloud2, and @R-maps.




```{r citacions, include=FALSE, message=FALSE}


# citation("compareGroups")
# citation("base")
# 
# knitr::write_bib(c("compareGroups","base", "ggplot2","wordcloud2", "maps"),file="references.bib")
# 

# 
# install.packages("bibtex")
# 
# refs<-read.bib("references.bib")
# 
# keys <- names(refs)
# 
# keys
# ?ggplot2

```


```{r capturar_tipus}


dt_temp<-readxl::read_excel(path_conductor,sheet = "journal_tipus") %>% select(TIPUS,Journal=agregador)

dades_journals<-
  dades_extra %>% filter(OBJECTE=="CUARTIL") %>% select(PMID,TIPUS,QUARTIL=VALOR) %>% left_join(dt_temp,by="TIPUS") %>% 
  left_join(select(dades,PMID,PUBYEAR),by="PMID")



```


```{r pais_autor}

# Capturar pais primer author
dt_paisos<-
  dades_extra %>% 
  filter(OBJECTE=="AUTHOR") %>% select(PMID,VALOR) %>% 
  mutate(pais=stringr::str_extract(VALOR, "(?<=,\\s)[^,]+$")) %>% 
  mutate(pais=stringr::str_extract(pais,"^[^.]*")) %>% 
  select(PMID,pais) %>% group_by(PMID) %>% slice(1) %>% ungroup() %>% 
  mutate(pais=iconv(pais, from = "UTF-8", to = "UTF-8//IGNORE")) %>% 
  mutate(pais=toupper(pais)) %>% 
  mutate(pais=stringr::str_trim(pais))


# Codis pais
dt_codis_pais<-
  dt_cataleg_countries %>% mutate(pais=toupper(Name)) %>% group_by(pais) %>% slice(1) %>% ungroup() %>% 
  select(id_pais=Id,pais) %>% 
   mutate(pais=stringr::str_trim(pais))

# Fusionar paisos

dt_paisos<-dt_paisos %>% left_join(dt_codis_pais, by="pais") %>% rename(Author_country=pais)


# Posar en dades de papers 
dades<-dades %>% left_join(dt_paisos, by="PMID")

# Capturar regions 
dt_regions<-read.csv(here::here("data","countries_regions.csv"), sep = ",") %>% 
  select(id_pais=alpha.2,region,subregion=sub.region) %>% 
  na.omit() %>% filter(id_pais!="" | region!=" ")

#
dades<-
  dt_regions %>% right_join(dades,by="id_pais") %>% 
  relocate(names(dades))

# Si Author_country==NA

# dades %>% distinct(Author_country,id_pais,region,subregion)


```


## Terms related to designs / Usability

- List of terms / synonyms searched for domains/designs

```{r llistat_termes}

# Open dt_termes_dissenys
dt_termes_dissenys<-readxl::read_excel(path_conductor,sheet = "termes") %>% filter(terme!=is.na(terme))

# En faig una llista 
llistat_dissenys<-split(dt_termes_dissenys$terme, dt_termes_dissenys$disseny)
vector_dissenys<-names(llistat_dissenys)

#
taula1<-
  dt_termes_dissenys %>% filter(classe=="design") %>% select(terme, disseny, tipo) %>% na.omit() %>% distinct() %>% 
  group_by(disseny) %>% mutate(id=1:n()) %>% arrange(disseny) %>% 
  mutate(disseny=if_else(id==1,disseny,"")) %>% 
  select(disseny,terme) 
  
taula1 %>% 
  kableExtra::kable(caption = "Table S1. List of terms in Abstract keywords titles related to designs") %>% kableExtra::kable_classic_2()

#
taula2<-dt_termes_dissenys %>% filter(classe=="dimension") %>% select(terme, dimensio=disseny) %>% distinct() %>% 
  group_by(dimensio) %>% mutate(id=1:n()) %>% mutate(dimensio=if_else(id==1,dimensio,"")) %>% select(dimensio,terme)

#
taula2 %>% 
  kableExtra::kable(caption = "Table S2. List of terms in Abstract/Keywords/Title according to Dimension or Scope of Application") %>% 
  kableExtra::kable_classic_2()



```

```{r test_officer, eval=TRUE}



# tt<-dt_termes_dissenys %>% filter(classe=="dimension") %>% select(terme, dimensio=disseny) %>% distinct() %>% 
#   group_by(dimensio) %>% mutate(id=1:n()) %>% mutate(dimensio=if_else(id==1,dimensio,"")) %>% select(dimensio,terme) %>% 
#   flextable::flextable() 

# Formatejar a flextable taula 1
tt<-taula1 %>% 
  flextable::flextable() %>% 
  flextable::theme_zebra() %>% 
  flextable::set_caption("Table S1. List of terms in Abstract/Keywords/Title according to Dimension or Scope of Application") %>% 
  flextable::autofit()

# Export to word taula1
officer::read_docx() %>%                        # creating a null .docx object
  flextable::body_add_flextable(value = tt) %>%   # insert the flextable object
  print(target = path_docs)  


# Formatejar a flextable taula 2
tt<-taula2 %>% 
  flextable() %>% 
  flextable::theme_zebra() %>% 
  set_caption("Table S2. List of terms in Abstract/Keywords/Title according to Dimension or Scope of Application") %>% 
  autofit()
  
# Export to word taula1
officer::read_docx(path_docs) %>%                 # creating a null .docx object
  flextable::body_add_flextable(value = tt) %>%   # insert the flextable object
  print(target = path_docs)  

# set_flextable_defaults(
#   font.size = 10, theme_fun = theme_vanilla,
#   padding = 6,
#   background.color = "#EFEFEF")
# 
# tt
# theme_vanilla(tt)


# ?kableExtra::kable()

```

# Results


```{r results_comentats}


```


The search provided a total of `r n_count` papers. In the Wordcloud, it can be observed that the most frequent keywords refer to mobile health, eHealth, and validation. Out of the total `r n_count` papers, epidemiological designs were identified in 528 of them, of which 41.3% were classified as clinical trials, while the rest were observational studies or systematic reviews. Among the works where the epidemiological design was identified, 54% were observational.

Of all the references found, the most frequent dimension was Usability (n=261, 18.4%), followed by Security (13.8%), and Feasibility (10.6%).

Table and figure shows the frequency of papers found per dimensions depending on whether the studies could be classified as observational or experimental. Significant differences (p<0.05) are observed in the dimensions of Feasibility (Proof of concept), and Effectiveness, with greater representation in experimental studies compared to observational studies. The rest of the dimensions show similar frequencies, except for the dimension of Efficacy, where there is also more representation in experimental studies (10.6% versus 5.8%).

Regarding the scope of application where they are published, 21.5% of the articles were found in Health care sciences, and 19% in journals related to medical informatics. The frequency of papers has exponentially increased, being more frequent in journals classified in quartiles 1 or 2.

The authors who publish the most are mainly from the United States (24.2%), followed by European countries such as the UK (8.07%), Spain, Germany, and Australia.


## Limitations on Interpretation

The bibliometric study is based on the automatic search of words, which entails certain intrinsic limitations that must be taken into account in interpretation. This includes lack of context, language evolution, synonyms, and linguistic variations that may use different words or phrases to describe similar concepts, which can lead to underrepresentation or overrepresentation of the identified dimensions and designs.



## Wordcloud Keywords

```{r wordcloud, include=FALSE}
paraula<-"KEYWORD"

freq_keyword<-
  dades_extra %>% filter(OBJECTE==paraula) %>% 
  mutate(VALOR=iconv(VALOR,to = "UTF-8", sub = "")) %>% 
  mutate(VALOR=tolower(VALOR)) %>% 
  group_by(VALOR) %>% count() %>% arrange(desc(n)) %>% filter(n>=2) %>% 
  mutate(word=VALOR,freq=n) %>% ungroup() %>% select(word,freq)



set.seed(123)
world_cloud_keywords<-wordcloud2(freq_keyword,size = 2,shuffle =F)
# world_cloud_keywords<-wordcloud2(freq_keyword,size = 2,shuffle =F,color="random-light")

# world_cloud_keywords

# ?wordcloud2

# wordcloud2(freq_keyword,size = 2,shuffle =F,color=rep_len( c("green","blue","orange","red"), nrow(freq_keyword)))

htmlwidgets::saveWidget(world_cloud_keywords, "wordcloud.html", selfcontained = F)
webshot::webshot("wordcloud.html", file="wordcloud.png", delay = 5, vwidth = 1000, vheight = 1000)

# {width=100%, height=100% }

```

![](wordcloud.png){width=400% height=400% }




## Wordcloud Mesh Terms

```{r Wordcloud2, include=FALSE}

paraula<-"MESH"

freq_keyword<-
  dades_extra %>% filter(OBJECTE==paraula) %>% group_by(VALOR) %>% count() %>% arrange(desc(n)) %>% filter(n>=2) %>% 
  mutate(word=VALOR,freq=n) %>% ungroup() %>% select(word,freq)


freq_keyword$word<-freq_keyword$word %>% iconv(to = "UTF-8", sub = "")


set.seed(124)
world_cloud_mesh<-wordcloud2(freq_keyword,size = 2,shuffle =F)

saveWidget(world_cloud_mesh, "tmp2.html", selfcontained = F)
webshot("tmp2.html", "wc2.png", delay = 5, vwidth = 1000, vheight = 1000)


# and in png or pdf
# webshot("tmp.html","fig_1.pdf", delay =5, vwidth = 480, vheight=480)


```


![](wc2.png){width=400% height=400% }




```{r salvar_en_docs, eval=TRUE}

officer::read_docx(path_docs) %>% 
  officer::body_add_img("wordcloud.png",height = 5, width = 5) %>% 
  print(target = path_docs)  


officer::read_docx(path_docs) %>% 
  officer::body_add_img("wc2.png",height = 5, width = 5) %>% 
  print(target = path_docs)  

```



```{r captura_dissenys}

# Captura dissenys/ dimensions
dt_temp<-dades_extra %>% filter(OBJECTE=="ABSTRACT") %>% select(PMID,text=VALOR)

# Afegeixo titul + keyword 
dt_temp2 <- dades_extra %>% filter(OBJECTE=="KEYWORD") %>% select(PMID,text=VALOR)
dt_temp3 <- dades %>% select(PMID,Article) %>% select(PMID,text=Article)
#
dt_temp<-dt_temp %>% bind_rows(dt_temp2,dt_temp3) %>% arrange(PMID)



# Generar variables dummies para cada palabra en el tibble
for (i in 1:length(llistat_dissenys)) {
  generar_dummy <- function(texto, patron) {any(stri_detect_fixed(texto, patron, case_insensitive = TRUE))}
  patro<-llistat_dissenys[[i]]
  
  dt_temp <- dt_temp %>% rowwise() %>% 
    mutate(!!names(llistat_dissenys[i]) := as.numeric(generar_dummy(text,patro)))}


## Agregar per PMID
dt_temp<-dt_temp %>% select(-text) %>%
  group_by(PMID) %>% 
    summarise_all(sum) %>% 
  ungroup() %>% 
  mutate_at(vector_dissenys, ~if_else(.>0,1,0))

## Disseny
dt_temp<-dt_temp %>% mutate(Design = rowSums(.[vector_dissenys])) %>% 
  mutate(Design=if_else(Design>0,1,0)) %>% relocate(PMID,Design)


dades<-dades %>% left_join(dt_temp,by="PMID")


```



```{r Open_dt_termes_dissenys, eval=FALSE}

# Open dt_termes_dissenys
dt_termes_usability<-readxl::read_excel(path_conductor,sheet = "terms_usability") 

# En faig una llista 
llistat_usability<-split(dt_termes_usability$terme, dt_termes_usability$tipus)
vector_usability<-names(llistat_usability)


dt_termes_usability %>% kableExtra::kable() %>% kableExtra::kable_classic_2()



```




```{r Generar_Dissenys_excloents}
## Generar Dissenys excloents

dt_temp<-dades %>% mutate(Design_tipo=case_when(RCT==1      ~"Clinical Trial",
                                    Cohort==1   ~ "Cohort",
                                    `Case-control` == 1 ~ "Case-control",
                                    `Cross-sectional` == 1 ~ "Cross-sectional",
                                    `Systematic review`== 1 ~ "Systematic review"
                                    ))

# table(dt_temp$Design_tipo) %>% sum()

# Observational / experimental
observational_terms<-dt_termes_dissenys %>% filter(tipo=="Observational") %>% pull(disseny)
experimental_terms<-dt_termes_dissenys %>% filter(tipo=="Experimental") %>% pull(disseny)


dt_temp<-dt_temp %>% 
  mutate(study_type= case_when(Design_tipo %in% observational_terms ~ "Observational",
                               Design_tipo %in% c("Clinical Trial") ~ "Experimental", 
                               TRUE ~ NA_character_
                               ))


dades<-dt_temp

```


```{r Arreglar_noms_de_variables}
# Arreglar noms de variables

source("funcions_format.R")

dades<-netejar.noms.variables(dades)



```



```{r recode_SINO}

# Yes No 
# vars_SINO<-FormatGe::extreure.variables("SiNo",path_conductor)
vars_SINO<-extreure.variables("SiNo",path_conductor)

dades<-dades %>% mutate_at(vars_SINO,~if_else(.==1,"Yes","No"))


```



```{r etiquetar_vars}


dades<-dades %>% etiquetar(path_conductor)


```

## Descriptive tables

- `r paste0("Global; n=", length(dades[,1]))`



```{r descriptivaI}

# Problemes amb els noms dels camps per fer descriptiva

# formu<-FormatGe::formula_text("Baseline","",taulavariables = path_conductor)
formu<-FormatGe::formula_text("Baseline","",taulavariables = path_conductor)

T1<-descrTable( formu , method = 3, hide = "No", data=dades) 

T1 %>% export2md()


# Problemes amb els noms dels camps per fer descriptiva
# formu<-FormatGe::formula_text("tipo","",taulavariables = path_conductor)
formu<-formula_text("tipo","",taulavariables = path_conductor)

T2<-descrTable( formu , method = 3, hide = "No", data=dades, show.n = F) 

T2 %>% export2md()


# formu<-FormatGe::formula_text("dimensio","",taulavariables = path_conductor)
formu<-formula_text("dimensio","",taulavariables = path_conductor)

T3 <- descrTable( formu , method = 3, hide = "No", data=dades, show.n = F) 

T3 %>% export2md()


# formu<-FormatGe::formula_text("dimensio","Design_tipo",taulavariables = path_conductor)
# descrTable( formu , method = 3, hide = "No", data=dades, show.n = T, byrow = F) %>% export2md()


formu<-FormatGe::formula_text("dimensio","study_type",taulavariables = path_conductor)
T4 <- descrTable( formu , method = 3, data=dades, show.n = T, byrow = F, hide = "No") 

T4 %>% export2md()
# 

```


```{r funcio_plot}

plot_barres<-function(pregunta="dimensio",dt=dades,var_tabac="study_type") {
  
  # pregunta="dimensio" 
  # dt=dades
  # var_tabac="study_type"
  # Figura multiresposta figura
  
  n_dades<-dt %>% count() %>% pull(n)
  
  if (n_dades>0) {
  
      dt_temp<-dt %>% select(extreure.variables(pregunta,path_conductor),tabac_cat:=!!sym(var_tabac)) %>% na.omit()
    
      # t√≠tul de pregunta
      # titol<-read_conductor(path_conductor) %>% filter(camp==pregunta) %>% pull(descripcio)
      
      # Preparar dades per grups
      dt_overall<-dt_temp %>% tidyr::gather(camp,value) %>% 
        group_by(camp,value) %>% 
        summarise(n=n()) %>% 
        group_by(camp) %>% 
        mutate(Percentage = n/sum(n)*100) %>% 
        # Reordenar nivells de tabaquisme
        filter(value%in%c("Si","S√≠","Yes")) %>% 
        left_join(read_conductor(path_conductor),by="camp") %>% 
        mutate(grup="Total", Overall="Total")  %>% 
        ungroup()
      
      # Ordeno overall per Percentatge de mes a menys 
      dt_overall<-dt_overall %>% arrange(desc(Percentage)) %>% mutate(ordreid=1:n()) 
      dt_ordre<-dt_overall %>% select(camp,ordreid)
      # tidyr::gather()
      
        # Preparar per grups 
      dt_grups<-dt_temp %>% 
        split(.$tabac_cat) %>% 
        purrr::map_df(~tidyr::gather(.x,camp,value),.id="grup") %>% 
        group_by(grup,camp,value) %>% 
        summarise(n=n()) %>% 
        group_by(grup,camp) %>% 
        mutate(Percentage = n/sum(n)*100) %>% 
        ungroup() %>% 
        # mutate (grup=factor(grup,levels=c("No fumador/a","Exfumador/a","Fumador/a"))) %>% 
        filter(value%in%c("Si","S√≠", "Yes")) %>% 
        left_join(read_conductor(path_conductor),by="camp") 
      
      # Ordeno preguntes de mens a mes Freq
      dt_grups<-dt_grups %>% left_join(dt_ordre) %>% arrange(ordreid)
      
      dt_grups %>% 
        ggplot(aes(x=ordreid, y=Percentage,fill=grup))+
        geom_bar(stat = "identity",position="dodge") +
        geom_bar(data=dt_overall,aes(x=ordreid, y=Percentage,color=Overall),
                 fill="black",colour=NA,alpha=1/10,stat = "identity",position="dodge") +
        scale_x_continuous(breaks = dt_overall$ordreid, labels = dt_overall$descripcio)+
        theme(axis.text.x=element_text(angle=45,hjust=1),legend.title=element_blank() )+
        labs(title = "Frequency of works identified for each dimension",x="",y="Porcentaje (%)", subtitle = "According study type")+
        scale_fill_brewer(palette = "Set2")
      } 
  
    }



```


```{r export_word, eval=TRUE, include=FALSE}

# Afegir taula, previament salvada
# Generar taula , salvar-la en word 
T1 %>% export2word("temp1.docx") 
T2 %>% export2word("temp2.docx") 
T3 %>% export2word("temp3.docx") 
T4 %>% export2word("temp4.docx") 

# Afegir taules en un word
officer::read_docx(path_docs) %>% 
  officer::body_add_docx("temp1.docx") %>% 
  officer::body_add_docx("temp2.docx") %>% 
  officer::body_add_docx("temp3.docx") %>% 
  officer::body_add_docx("temp4.docx") %>% 
  print(path_docs)


gg_pp<-plot_barres(pregunta="dimensio",dt=dades,var_tabac="study_type")


#  Afegir ggplot
officer::read_docx(path_docs) %>% 
  officer::body_add_gg(gg_pp) %>% 
  print(path_docs)

# clean files 

files_clean<-c("temp1.docx","temp2.docx","temp3.docx","temp4.docx","temp1.Rmd","temp2.Rmd","temp3.Rmd","temp4.Rmd", "temp2.html")

file.remove(files_clean)

  
```




## Journal Description by Domain

```{r descript_journal}

# Agafo els 10/15 m√©s frequents
Journal_tipo_freq<-dades_journals %>% group_by(Journal) %>% count() %>% arrange(desc(n)) %>% ungroup() %>% mutate(id=1:n()) %>% filter(id<20) %>% pull(Journal)

# Colapsar las categor√≠as poco frecuentes (C y D) en una sola categor√≠a "Otros"
dt_temp<-dades_journals %>% mutate(Journal=if_else(Journal%in%Journal_tipo_freq, Journal,"Others"))


# Reordenamos las categor√≠as por frecuencia
dt_temp$Journal <- factor(dt_temp$Journal,levels = names(sort(table(dt_temp$Journal),
                                                     decreasing = TRUE)))


# # Fer taula
# dt_temp %>% group_by(Journal) %>% count() %>% arrange(desc(n))

#
T3<-table1::table1(~Journal,data=dt_temp, footnote="Others: frequency < 1%")

T3




```

```{r export_t3, eval=TRUE}


# Converteixo a flextable
T3 <- table1::t1flex(T3, tablefn = c("qflextable", "flextable", "regulartable")) 

# Afegir a docs
officer::read_docx(path_docs) %>% 
  body_add_flextable(T3) %>% 
  print(target = path_docs)  



```


### Figura

```{r figura_papers_scope}
# Figura de frequencies

# Colapsar las categor√≠as poco frecuentes (C y D) en una sola categor√≠a "Otros"
dt_temp<-dades_journals %>% mutate(Journal=if_else(Journal%in%Journal_tipo_freq, Journal,"Others"))

# Journal a minuscula
dt_temp<-
  dt_temp %>% mutate(Journal=tolower(Journal)) %>% 
  mutate(Journal= paste(toupper(substr(Journal, 1, 1)), substr(Journal, 2, nchar(Journal)), sep = ""))
  

dt_temp2<-dt_temp %>% group_by(Journal) %>% count() 

source("funcions_plots.R")

fig3<-generar_plot_estimacions_profile()

fig3

#  Afegir ggplot
officer::read_docx(path_docs) %>% 
  officer::body_add_gg(fig3) %>% 
  print(path_docs)


```


## Evolution of the frequency of published papers 

- According to quartile journal
- According to scope of the journal

```{r evolucio_freq_papers}
# VAriable tipus 
# Agafo els 10/15 m√©s frequents
Journal_tipo_freq<-dades_journals %>% group_by(Journal) %>% count() %>% arrange(desc(n)) %>% ungroup() %>% mutate(id=1:n()) %>% filter(id<10) %>% pull(Journal)

# Colapsar las categor√≠as poco frecuentes (C y D) en una sola categor√≠a "Otros"
dt_temp<-dades_journals %>% mutate(Journal=if_else(Journal%in%Journal_tipo_freq, Journal,"Others"))


dt_temp<-dt_temp %>% select(PMID,TIPUS, Quartil=QUARTIL,PUBYEAR,Journal)

# Agregaci√≥ per any x quartil

dt_temp3<-dt_temp %>% group_by(PUBYEAR) %>% count() %>% na.omit() %>% ungroup() %>% mutate(Quartil="Overall") %>% filter(Quartil!="N/A") 

dt_temp2<-dt_temp %>% group_by(PUBYEAR,Quartil) %>% count() %>% na.omit() %>% ungroup() %>% filter(Quartil!="N/A") 

dt_temp2<-dt_temp2 %>% bind_rows(dt_temp3) %>% arrange(PUBYEAR,Quartil) %>% 
  filter(PUBYEAR<2023 & PUBYEAR>2005)


# dt_temp2

# Gg-plot 
fig4<-ggplot(dt_temp2, aes(x = PUBYEAR, y = n, group = Quartil, color = Quartil)) +
  # geom_line(size=1) +
  geom_smooth(method = "loess", se = FALSE) +
  labs(title = "Evolution of the papers indexed in PubMed by Quartile",
       x = "Year of publication",
       y = "Frequency",
       color = "Quartile") + ggplot2::theme_light() +
  
   scale_x_continuous(breaks = seq(min(dt_temp2$PUBYEAR), max(dt_temp2$PUBYEAR), by=2)) +
   
   scale_color_manual(values = c("Overall" = "orange","Q1"="red4","Q2"="blue1",Q3="green4",Q4="purple")) + 
  
   theme(legend.position = "top",
        legend.text = element_text(size = 7)) 
  

  
fig4
 

```



```{r evolucio_papers_2}

# Por terminos / ambitos

# VAriable tipus 
# Agafo els 10/15 m√©s frequents
Journal_tipo_freq<-dades_journals %>% group_by(Journal) %>% count() %>% arrange(desc(n)) %>% ungroup() %>% 
  mutate(id=1:n()) %>% filter(id<5) %>% pull(Journal)

# Colapsar las categor√≠as poco frecuentes (C y D) en una sola categor√≠a "Otros"
dt_temp<-dades_journals %>% mutate(Journal=if_else(Journal%in%Journal_tipo_freq, Journal,"Others")) %>% filter(Journal!="Others")


dt_temp<-dt_temp %>% select(PMID,TIPUS, Quartil=QUARTIL,PUBYEAR,Journal)


# Agregaci√≥ per any
dt_temp2<-dt_temp %>% group_by(PUBYEAR,Journal) %>% count() %>% na.omit() %>% ungroup() %>% filter(Journal!="N/A") %>% 
  filter(PUBYEAR<2023 & PUBYEAR>2005)

# Gg-plot 
fig5<-
  ggplot(dt_temp2, aes(x = PUBYEAR, y = n, group = Journal, color = Journal)) +
  # geom_line(size=1) +
  geom_smooth(method = "loess", se = FALSE) +
  labs(title = "Evolution of the frequency papers indexed in PubMed by scope",
       x = "Year of publication",
       y = "Frequency",
       color = "") +
  
  scale_x_continuous(breaks = seq(min(dt_temp2$PUBYEAR), max(dt_temp2$PUBYEAR), by=2)) +
  
  ggplot2::theme_light() +
  theme(legend.position = "top",
        legend.text = element_text(size = 6)) 
  

fig5


```


```{r export_figures}

#  Afegir ggplot
officer::read_docx(path_docs) %>% 
  officer::body_add_gg(fig4) %>% 
  print(path_docs)


#  Afegir ggplot
officer::read_docx(path_docs) %>% 
  officer::body_add_gg(fig5) %>% 
  print(path_docs)


```


## Frequency papers by country and region

```{r papers_regions, eval=T, include=TRUE}


n_dades<-length(dades$PMID)
n_dades_pais<-dades %>% select(id_pais,region) %>% filter(!is.na(region)) %>% count() %>% as.numeric()

T5<-dades %>% 
  mutate(Author_country=if_else(Author_country=="USA","UNITED STATES",Author_country)) %>% 
  mutate(Author_country=if_else(Author_country=="UK","UNITED KINGDOM",Author_country)) %>% 
  group_by(Author_country) %>% count() %>% arrange(desc(n)) %>% ungroup() %>% 
  mutate(per=(n/n_dades_pais)*100) %>% 
  filter(!is.na(Author_country)) %>% 
  mutate(id=1:n()) %>% filter(id<20) %>% select(Author_country,n,`%`=per) 

T5 %>% 
  kableExtra::kable(digits = 2) %>% kableExtra::kable_classic_2()


T6<-table1::table1(~ subregion + region, data=dades)

T6


```

```{r exportT5}

# Formatejar a flextable taula 5
T5<-T5 %>% 
  flextable::flextable() %>% 
  flextable::theme_zebra() %>% 
  flextable::autofit()

# Export to word taula5
officer::read_docx(path_docs) %>%                        # creating a null .docx object
  flextable::body_add_flextable(value = T5) %>%   # insert the flextable object
  print(target = path_docs)  


T6 <- table1::t1flex(T6, tablefn = c("qflextable", "flextable", "regulartable")) 

# Afegir a docs
officer::read_docx(path_docs) %>% 
  body_add_flextable(T6) %>% 
  print(target = path_docs)  


```


```{r generar_dades_mapa}

# Cargar el mapa mundial
mapa_mon <- map_data("world")


# Capturar codi iso2c 
tabla_codigos <- countrycode(
  sourcevar = unique(mapa_mon$region), 
  origin = c("country.name.en"), 
  destination = "iso2c")

pp<-tibble(region=unique(mapa_mon$region),id_pais=tabla_codigos)

mapa_mon<-mapa_mon %>% left_join(pp,by="region")


# Falta afegir subregio
# Capturar regions 
dt_regions<-read.csv(here::here("data","countries_regions.csv"), sep = ",") %>% 
  select(id_pais=alpha.2,region1=region,subregion=sub.region)

dt_regions<-dt_regions %>% filter(!is.na(id_pais))

mapa_mon<-mapa_mon %>% select(-subregion) %>% left_join(dt_regions,by=c("id_pais"))

# mapa_mon %>% filter(is.na(id_pais))

# Capturar frequencies d'articles
```


```{r mapa_subregions, eval=TRUE}

# Agregaci√≥ per subregions
freqs_subregions<-dades %>% group_by(subregion) %>% count() %>% ungroup() %>% filter(!is.na(subregion))

# dades %>% group_by(subregion) %>% count() %>% ungroup() %>% arrange(desc(n))

datos_mapa<-mapa_mon %>% 
  # filter(is.na(subregion)) %>% 
  left_join(freqs_subregions) %>% rename(frecuencia=n)

# Crear el plot de mapa de frecuencias
gg_map1<-
  ggplot(datos_mapa, aes(x = long, y = lat, group = group, fill = frecuencia)) +
  geom_polygon() +
  coord_fixed(ratio = 1.6) + # Relaci√≥n de aspecto para proyectar el mapa correctamente
  scale_fill_gradient(low = "orange1", high = "orange4") +
  labs(title = "Frequency Map of Papers by regions",
       fill = "Frequency",
       caption = "Grey colour: No data",
       x = "", y = "") +
  theme_minimal()


gg_map1




# freqs_subregions %>% distinct(subregion) %>% pull(subregion)

```


```{r test_pais_origen, eval=FALSE}

dades %>% group_by(id_pais) %>% count() %>% ungroup() %>% arrange(desc(n))
dades %>% group_by(Author_country) %>% count() %>% ungroup() %>% arrange(desc(n))


```


```{r mapa_per_pais}

# Mapa per pais

# Capturar frequencies d'articles
# Agregaci√≥ per subregions
freqs_pais<-dades %>% group_by(id_pais) %>% count() %>% ungroup()
datos_mapa<-mapa_mon %>% left_join(freqs_pais) %>% rename(frecuencia=n)

# Crear el plot de mapa de frecuencias
gg_map2<-
  ggplot(datos_mapa, aes(x = long, y = lat, group = group, fill = frecuencia)) +
  geom_polygon() +
  coord_fixed(ratio = 1.6) + # Relaci√≥n de aspecto para proyectar el mapa correctamente
  scale_fill_gradient(low = "orange", high = "orange4") +
  labs(title = "Frequency Map of Papers by Countries Worldwide",
       fill = "Frequency",
       x = "", y = "", caption = "Grey colour: No data") +
  theme_minimal()

gg_map2

```


```{r export_mapes}

#  Afegir ggplot
officer::read_docx(path_docs) %>% 
  officer::body_add_gg(gg_map1) %>% 
  print(path_docs)


#  Afegir ggplot
officer::read_docx(path_docs) %>% 
  officer::body_add_gg(gg_map2) %>% 
  print(path_docs)


```


```{r salvar_figures, include=FALSE}


ggsave(here::here("outputs","fig2B.png"), fig3)

ggsave(here::here("outputs","fig2A.png"), fig4)

ggsave(here::here("outputs","fig3A.png"),gg_map2)

ggsave(here::here("outputs","fig3A_regions.png"),gg_map1)

htmlwidgets::saveWidget(world_cloud_keywords, "wordcloud.html", selfcontained = F)

webshot::webshot("wordcloud.html", file=here::here("outputs","wordcloud.png"), delay = 5, vwidth = 1000, vheight = 1000)



```


# References


```{r references, include=FALSE}

knitr::write_bib(file = 'references.bib')


```


```
&nbsp;
<hr />
<p style="text-align: center;">A work by Jordi Real </a></p>
<p style="text-align: center;">CVCSD</a></p>
<p style="text-align: center;"><span style="color: #808080;"><em><https://github.com/CVCSD></em></span></p>


